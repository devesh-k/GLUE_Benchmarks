{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d79bc70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (2.19.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from datasets) (3.4.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.21.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.1.2)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.8/site-packages (from jupyter) (5.5.2)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.3.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.29.4)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.4.1)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (59.4.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.5.4)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.8.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (21.3)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (7.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (26.0.3)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (5.1.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.9)\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.3)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->jupyter) (2.0.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (4.2.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (21.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (3.6.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (21.1.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->ipykernel->jupyter) (3.0.6)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install --upgrade jupyter ipywidgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cad2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch, transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from datasets import load_dataset\n",
    "import pandas as pd, numpy as np\n",
    "from torch import cuda\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import datetime\n",
    "import warnings\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89dfe32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7defeea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "#global params for training\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", padding = True, return_tensors = \"pt\",is_split_into_words=True)\n",
    "batch_size = 32\n",
    "epoch = 100\n",
    "max_tokenizer_len = 512\n",
    "\n",
    "# train_loss_list = []\n",
    "# val_loss_list =[]\n",
    "if cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print(device)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "#print(device)\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "#os.environ[\"MKL_DEBUG_CPU_TYPE\"] = \"5\"\n",
    "glue_task = 'mrpc'\n",
    "labels = ['Class 0', 'Class 1']\n",
    "global_tr_loss = torch.inf\n",
    "global_val_loss = torch.inf\n",
    "#print(global_tr_loss)\n",
    "model_path = os.path.join(\"data\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87bb022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "#pip install datasets\n",
    "\n",
    "from datasets import load_dataset\n",
    "#mrpc = load_dataset('glue', 'sst2')\n",
    "\n",
    "dataset = load_dataset('glue','mrpc') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "126d7745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/msr_paraphrase_train.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3938"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset\n",
    "# msr_paraphrase_test.txt\n",
    "# msr_paraphrase_train.txt\n",
    "import pandas as pd , os\n",
    "file_path = os.path.join(\"data\",\"msr_paraphrase_train.txt\")\n",
    "print(file_path)\n",
    "\n",
    "df = pd.read_csv(file_path,sep='\\t', on_bad_lines='skip')\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7cd1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_temp = pd.DataFrame(dataset['train'])\n",
    "df_test = pd.DataFrame(dataset['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c14be287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1725"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c568c2",
   "metadata": {},
   "source": [
    "# Train Test split\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c387e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# Randomly shuffle the DataFrame\n",
    "df_shuffled = train_df_temp.sample(frac=1, random_state=seed)\n",
    "train_ratio = 0.8\n",
    "# Calculate the number of samples for training\n",
    "train_size = int(train_ratio * len(df_shuffled))\n",
    "\n",
    "# Split the shuffled DataFrame into training and testing sets\n",
    "df_train = df_shuffled[:train_size]\n",
    "df_val = df_shuffled[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "542b8ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2934\n",
      "734\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c94fb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Tibco has used the Rendezvous name since 1994 ...</td>\n",
       "      <td>Tibco has used the Rendezvous name since 1994 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>Most of the alleged spammers engaged in fraudu...</td>\n",
       "      <td>\" Spam knows no borders , \" said Brad Smith , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>Yesterday , Taiwan reported 35 new infections ...</td>\n",
       "      <td>The island reported another 35 probable cases ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>A month ago , the Commerce Department estimate...</td>\n",
       "      <td>A month ago , the Commerce Department said GDP...</td>\n",
       "      <td>1</td>\n",
       "      <td>1187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>Gillespie sent a letter to CBS President Lesli...</td>\n",
       "      <td>Republican National Committee Chairman Ed Gill...</td>\n",
       "      <td>0</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1  \\\n",
       "179   Tibco has used the Rendezvous name since 1994 ...   \n",
       "2679  Most of the alleged spammers engaged in fraudu...   \n",
       "3133  Yesterday , Taiwan reported 35 new infections ...   \n",
       "1061  A month ago , the Commerce Department estimate...   \n",
       "1091  Gillespie sent a letter to CBS President Lesli...   \n",
       "\n",
       "                                              sentence2  label   idx  \n",
       "179   Tibco has used the Rendezvous name since 1994 ...      1   201  \n",
       "2679  \" Spam knows no borders , \" said Brad Smith , ...      0  2977  \n",
       "3133  The island reported another 35 probable cases ...      1  3482  \n",
       "1061  A month ago , the Commerce Department said GDP...      1  1187  \n",
       "1091  Republican National Committee Chairman Ed Gill...      0  1220  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37682d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Lets check the labal distributions\n",
    "import seaborn as sns\n",
    "sns.countplot(data = df_train ,x = df_train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4d70e",
   "metadata": {},
   "source": [
    "### This dataset is imbalanced, calculating weight adjustments to pass to the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13c94353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[0, 0]\n",
      "[957, 1977]\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# get unique values for number of classes\n",
    "num_classes = len(df_train.label.unique())\n",
    "print(num_classes)\n",
    "# get the number of samples for each class\n",
    "class_dist = [0]*num_classes\n",
    "print(class_dist)\n",
    "# create a zero vector that equals the number of labels\n",
    "for i in range(num_classes):\n",
    "    class_dist[i]= (df_train['label']== i).sum()\n",
    "print(class_dist)\n",
    "class_dist = torch.tensor(class_dist)\n",
    "print(type(class_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "792f92a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5329, 0.7420])\n"
     ]
    }
   ],
   "source": [
    "#label_0_wt = len(df_train) / (num_samples_in_class_i * num_classes)\n",
    "weight_vector = torch.zeros(class_dist.shape)\n",
    "for i in range(num_classes):\n",
    "    weight_vector[i] = len(df_train) / (class_dist[i] * num_classes)\n",
    "print(weight_vector)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51bda4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the tokenizer:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", padding = True, return_tensors = \"pt\" , truncate = True, max_length  = 512)\n",
    "\n",
    "#encoding multiple sentences with a tokenizer https://discuss.huggingface.co/t/use-two-sentences-as-inputs-for-sentence-classification/5444/3\n",
    "\n",
    "encoding = tokenizer(df_train['sentence1'][9], df_train['sentence2'][9] , padding=\"max_length\", truncation=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc37dc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 156, 22705, 1116, 1104, 9066, 11656, 1732, 117, 170, 1277, 2610, 1419, 1114, 1317, 2982, 1113, 1103, 2319, 117, 3152, 1167, 1190, 123, 3029, 119, 102, 156, 22705, 1116, 1104, 161, 7903, 2204, 1479, 3029, 1107, 1346, 2597, 117, 1229, 6117, 1104, 9066, 11656, 1732, 117, 170, 1277, 2610, 1419, 1114, 1317, 2982, 1113, 1103, 2319, 117, 1127, 1146, 123, 3029, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eed3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb3ccc80",
   "metadata": {},
   "source": [
    "### Data loaders and Dataset for batched training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc56d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pyt(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.num_classes = len(df.label.unique())\n",
    "                \n",
    "    def __getitem__(self, idx):\n",
    "        text1 = self.df.iloc[idx]['sentence1']\n",
    "        text2 = self.df.iloc[idx]['sentence2']\n",
    "        x = tokenizer(text1,text2 ,padding=\"max_length\",truncation=True, return_tensors=\"pt\" )\n",
    "        #print(f\"inside the loader and index = {idx}\")\n",
    "        x_dict = {}\n",
    "        x_dict['id'] = x['input_ids']\n",
    "        x_dict['token_type'] = x['token_type_ids']\n",
    "        x_dict['attention_mask'] = x['attention_mask']\n",
    "        #label = torch.tensor(self.df.iloc[idx]['label'] , dtype=torch.float32)\n",
    "        label_onehot = torch.nn.functional.one_hot(torch.tensor(self.df.iloc[idx]['label']), num_classes= num_classes).float()\n",
    "        \n",
    "        #print(f\"inside the dataset class ..label_vec_t = {label_onehot}\")\n",
    "        return x_dict, label_onehot\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return the length of the dataframe\n",
    "        return len(self.df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72356fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13de5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset_pyt(df_train)\n",
    "val_dataset = dataset_pyt(df_val)\n",
    "test_dataset = dataset_pyt(df_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size = batch_size, shuffle = True , num_workers = 0, pin_memory = False)\n",
    "val_loader = DataLoader(val_dataset,batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test_dataset,batch_size = batch_size, shuffle = False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d200f73",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be2f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clf_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(clf_model, self).__init__()\n",
    "        self.backbone = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        #self.norm_layer = torch.nn.LayerNorm()\n",
    "        self.linear_layer = torch.nn.Linear(768, 2)\n",
    "         \n",
    "                  \n",
    "    def forward(self,ids ,token_type,att_mask):\n",
    "        #print(f\"shape of ids->{ids.shape}\")\n",
    "           #ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False     \n",
    "        _,x = self.backbone(ids , token_type_ids =token_type ,attention_mask= att_mask, return_dict=False)\n",
    "                \n",
    "        x = self.linear_layer(x)\n",
    "        #print(f\"shape after linear_layer->{x.shape}\")\n",
    "        #print(f\"x after linear ->{x}\")\n",
    "        #layer_norm = torch.nn.LayerNorm(x.shape[1])\n",
    "        #x = layer_norm(x)\n",
    "        #print(f\"x fter layer norm = {x}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f604e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.l2 = torch.nn.Dropout(0.3)\n",
    "class clf_model_drp(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(clf_model_drp, self).__init__()\n",
    "        self.backbone = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear_layer = torch.nn.Linear(768, 2)\n",
    "         \n",
    "                  \n",
    "    def forward(self,ids ,token_type,att_mask):\n",
    "        #print(f\"shape of ids->{ids.shape}\")\n",
    "           #ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False     \n",
    "        _,x = self.backbone(ids , token_type_ids =token_type ,attention_mask= att_mask, return_dict=False)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear_layer(x)\n",
    "        #print(f\"shape after linear_layer->{x.shape}\")\n",
    "        #print(f\"x after linear ->{x}\")\n",
    "        #layer_norm = torch.nn.LayerNorm(x.shape[1])\n",
    "        #x = layer_norm(x)\n",
    "        #print(f\"x fter layer norm = {x}\")\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62d88377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true,y_pred, labels):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)  # Adjust font scale for better readability\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfefb829",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def eval_model(val_loader, model, epoch , device = device,):\n",
    "    global global_val_loss\n",
    "    m = nn.Softmax()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    e = epoch+1\n",
    "    val_loss_list = []\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    print(f\"inside validation data for epoch {e}\")\n",
    "    y_hat_val_list = []\n",
    "    y_val_list = []\n",
    "    for ind,(x_dict, label_vec) in enumerate(val_loader):\n",
    "        model.to(device)\n",
    "        id_list = x_dict['id']\n",
    "        ids = torch.squeeze(torch.tensor(id_list, device = device),dim = 1).clone().detach()\n",
    "        tok_type_list = x_dict['token_type']\n",
    "        token_type = torch.squeeze(torch.tensor(tok_type_list, device = device),dim = 1).clone().detach()\n",
    "        att_list = x_dict['attention_mask']\n",
    "        att_mask = torch.squeeze(torch.tensor(att_list, device = device),dim = 1).clone().detach()\n",
    "        lab = label_vec.to(torch.device('cuda:0'))\n",
    "        logits = model(ids ,token_type,att_mask)\n",
    "        \n",
    "        probs = m(logits)\n",
    "        y_hat_val_list.append(torch.argmax(probs , dim = 1))\n",
    "        y_val_list.append(torch.argmax(lab , dim = 1))\n",
    "        \n",
    "        act_loss = criterion(logits, lab)\n",
    "        val_loss_list.append(act_loss.item())\n",
    "            \n",
    "    mean_val_loss = torch.mean(torch.tensor(val_loss_list))\n",
    "    if mean_val_loss < global_val_loss:\n",
    "        print(f\"Val loss has decreased -->reducing the global validation loss from {global_val_loss:.2f} to {mean_val_loss:.2f}\")\n",
    "        global_val_loss = mean_val_loss\n",
    "        print(f\" validation loss for epoch = {e} is {torch.mean(torch.tensor(val_loss_list)):.4f}\")\n",
    "        #print metrics and save the model\n",
    "        y_hat_val = torch.cat(y_hat_val_list)\n",
    "        y_val = torch.cat(y_val_list)\n",
    "        acc_val = accuracy_score(y_val.cpu().numpy(), y_hat_val.cpu().numpy())\n",
    "        f1_val = f1_score(y_val.cpu().numpy(), y_hat_val.cpu().numpy(), average='micro')\n",
    "        print(f\" epoch= {e} : mean val loss is {torch.mean(torch.tensor(mean_val_loss)):.4f} -> the accuracy is {acc_val:.2f} ->the f1 is {f1_val:.2f} \")\n",
    "        #save the model\n",
    "        \n",
    "        # Get the current date and time\n",
    "        current_datetime = datetime.datetime.now()\n",
    "        # Extract date and time components\n",
    "        current_date = str(current_datetime.date())\n",
    "        current_time = str(current_datetime.time()).split('.')[0]\n",
    "        file_name = 'model'+ current_date+current_time+'_'+glue_task+'.pth'\n",
    "        path = os.path.join(\"model\",file_name)\n",
    "        print(f\"saving the model {file_name}\")\n",
    "        torch.save(model.state_dict(), path)\n",
    "        plot_confusion_matrix(y_val.cpu().numpy(), y_hat_val.cpu().numpy(), labels)\n",
    "    else:\n",
    "        print(f\"No improvement in validation loss-->epoch= {e} and global val loss is {global_val_loss:.4f}\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2760357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader,val_loader ,num_epoch = 10, model = clf_model(),device = device, class_weights = weight_vector):\n",
    "    global global_tr_loss\n",
    "    model.train()\n",
    "    device = device\n",
    "    print(f\"inside train model. Device = {device}\")\n",
    "    optimizer = torch.optim.Adam(params =  model.parameters(), lr= 5e-5)\n",
    "    model.to(device)\n",
    "    wt = class_weights.to(device = device)\n",
    "    m = nn.Softmax()\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(weight = wt)\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda = lambda epoch : 0.95 ** epoch)\n",
    "    \n",
    "    for i in range (num_epoch):\n",
    "        y_hat_list =[]\n",
    "        label_list = []\n",
    "        epoch_train_loss = []\n",
    "        for ind,(x_dict, label_vec) in enumerate(train_loader):\n",
    "            id_list = x_dict['id']\n",
    "            ids = torch.squeeze(torch.tensor(id_list, device = device),dim = 1).clone().detach()\n",
    "            tok_type_list = x_dict['token_type']\n",
    "            token_type = torch.squeeze(torch.tensor(tok_type_list, device = device),dim = 1).clone().detach()\n",
    "            att_list = x_dict['attention_mask']\n",
    "            att_mask = torch.squeeze(torch.tensor(att_list, device = device),dim = 1).clone().detach()\n",
    "            lab = label_vec.to(device = device)\n",
    "            #predictions\n",
    "            logits = model(ids ,token_type,att_mask)\n",
    "            probs = m(logits)\n",
    "            y_hat_list.append(torch.argmax(probs , dim = 1))\n",
    "            label_list.append(torch.argmax(lab, dim = 1))\n",
    "            \n",
    "            #loss calculation                   \n",
    "            act_loss = criterion(logits, lab)\n",
    "            epoch_train_loss.append(act_loss.item())\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            act_loss.backward()\n",
    "            \n",
    "        #batch processing complete    \n",
    "        mean_loss = torch.mean(torch.tensor(epoch_train_loss))\n",
    "        \n",
    "        if mean_loss < global_tr_loss:\n",
    "            print(f\"training loss has decreased---> reducing the global loss from {global_tr_loss:.2f} to {mean_loss:.2f}\")\n",
    "            global_tr_loss = mean_loss\n",
    "            print(f\" epoch= {i+1} and mean train loss is {torch.mean(torch.tensor(epoch_train_loss)):.4f}\")\n",
    "            #printing training metrices\n",
    "            y_hat = torch.cat(y_hat_list)\n",
    "            y = torch.cat(label_list)\n",
    "            acc = accuracy_score(y.cpu().numpy(), y_hat.cpu().numpy())\n",
    "            f1 = f1_score(y.cpu().numpy(), y_hat.cpu().numpy(), average='micro')\n",
    "            print(f\" epoch= {i+1} : mean train loss is {torch.mean(torch.tensor(epoch_train_loss)):.4f} -> the accuracy is {acc:.2f} ->the f1 is {f1:.2f} \")\n",
    "            #checking validation metrices\n",
    "            eval_model(val_loader, model, epoch = i , device = device)\n",
    "            \n",
    "        else:\n",
    "            print(f\"No improvement in training loss..the global training loss is -->{global_tr_loss:.2f} \")\n",
    "            print(f\" epoch= {i+1} and mean train loss is {torch.mean(torch.tensor(epoch_train_loss)):.4f}\")\n",
    "        \n",
    "        print(f\"current LR->{scheduler.get_last_lr()}\")\n",
    "        scheduler.step()\n",
    "        print(f\"POST SCHEDULER.step LR->{scheduler.get_last_lr()}\")\n",
    "    \n",
    "    return model\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09988b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside train model. Device = cuda:0\n",
      "training loss has decreased---> reducing the global loss from inf to 0.83\n",
      " epoch= 1 and mean train loss is 0.8303\n",
      " epoch= 1 : mean train loss is 0.8303 -> the accuracy is 0.33 ->the f1 is 0.33 \n",
      "inside validation data for epoch 1\n",
      "Val loss has decreased -->reducing the global validation loss from inf to 0.75\n",
      " validation loss for epoch = 1 is 0.7523\n",
      " epoch= 1 : mean val loss is 0.7523 -> the accuracy is 0.32 ->the f1 is 0.32 \n",
      "saving the model model2024-05-1413:26:44_mrpc.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current LR->[5e-05]\n",
      "POST SCHEDULER.step LR->[4.75e-05]\n",
      "No improvement in training loss..the global training loss is -->0.83 \n",
      " epoch= 2 and mean train loss is 0.8314\n",
      "current LR->[4.75e-05]\n",
      "POST SCHEDULER.step LR->[4.5125e-05]\n",
      "No improvement in training loss..the global training loss is -->0.83 \n",
      " epoch= 3 and mean train loss is 0.8314\n",
      "current LR->[4.5125e-05]\n",
      "POST SCHEDULER.step LR->[4.2868749999999995e-05]\n",
      "No improvement in training loss..the global training loss is -->0.83 \n",
      " epoch= 4 and mean train loss is 0.8314\n",
      "current LR->[4.2868749999999995e-05]\n",
      "POST SCHEDULER.step LR->[4.07253125e-05]\n"
     ]
    }
   ],
   "source": [
    "model = clf_model_drp()\n",
    "\n",
    "\n",
    "#train_loader,optimizer,val_loader ,num_epoch = 100, model = clf_model()\n",
    "tr_model = train_model(train_loader, val_loader )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caeda25",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604973c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add84ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78956e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04863d62",
   "metadata": {},
   "source": [
    "def train_model_debug(train_loader,optimizer,val_loader ,num_epoch = 50, model = clf_model_debug()):\n",
    "    model.train()\n",
    "    for ind,(x_dict, label_vec) in enumerate(train_loader):\n",
    "        model.to(device)\n",
    "        #print(next(model_gpu.parameters()).device)\n",
    "\n",
    "        id_list = x_dict['id']\n",
    "        id_tensor = torch.squeeze(torch.tensor(id_list),dim = 1)\n",
    "        #print(f\"shape of ids->{id_tensor.shape}\")\n",
    "\n",
    "        tok_type_list = x_dict['token_type']\n",
    "        tok_type_tensor = torch.squeeze(torch.tensor(tok_type_list),dim = 1)\n",
    "\n",
    "        #token_type = torch.squeeze(torch.tensor(,dtype=torch.long).clone().detach(), dim = 1)\n",
    "        #print(f\"shape of token_type->{tok_type_tensor.shape}\")\n",
    "\n",
    "        att_list = x_dict['attention_mask']\n",
    "        att_mask_tensor = torch.squeeze(torch.tensor(att_list),dim = 1)\n",
    "        #att_mask = torch.squeeze(torch.tensor(,dtype=torch.long).clone().detach(), dim = 1)\n",
    "        #print(f\"shape of att_mask->{att_mask_tensor.shape}\")\n",
    "\n",
    "        ids_gpu = id_tensor.to(device)\n",
    "        #print(f\"ids = {ids_gpu}\")\n",
    "        #ids.to(device)\n",
    "        #print(ids_gpu.device)\n",
    "\n",
    "        token_type_gpu = tok_type_tensor.to(device)\n",
    "        #print(token_type_gpu.device)\n",
    "\n",
    "        att_mask_gpu = att_mask_tensor.to(device)\n",
    "        #print(att_mask_gpu.device)\n",
    "\n",
    "\n",
    "\n",
    "        labal_vec_gpu = label_vec.float().to(device)\n",
    "        #print(f\" labal_vec_gpu = {labal_vec_gpu}\")\n",
    "\n",
    "        logits = model(ids_gpu ,token_type_gpu,att_mask_gpu)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss = nn.BCELoss()\n",
    "        output = loss(logits, labal_vec_gpu)\n",
    "        #print(f\"loss for batch_index->{ind} is {output.item()}\")\n",
    "\n",
    "        #loss = torch.nn.BCEWithLogitsLoss(logits, labal_vec_gpu)\n",
    "        output.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_list.append(output.item())\n",
    "        print(f\"batch_ind{ind} and its loss is {output.item()}\")\n",
    "\n",
    "        #print(f\" epoch= {i} and mean train loss is {torch.mean(torch.tensor(train_loss_list))}\")\n",
    "        #eval_model(val_loader, model, i , device = device)\n",
    "        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ad513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac08e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
